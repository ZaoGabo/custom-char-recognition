{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CNN v3 SUPER - Entrenamiento Intensivo ğŸ”¥\n",
                "\n",
                "Modelo mÃ¡s profundo, mÃ¡s Ã©pocas, TODO el dataset.\n",
                "\n",
                "**Setup:**\n",
                "1. Runtime > Change runtime type > **GPU (T4)**\n",
                "2. Run all cells\n",
                "3. Espera ~30-40 minutos\n",
                "4. Descarga el `.onnx` al final\n",
                "\n",
                "**Objetivo:** >90% accuracy en EMNIST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
                        "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m683.0/683.0 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25h"
                    ]
                }
            ],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install -q torch torchvision torchaudio albumentations onnx onnxruntime onnxscript\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ® Device: cuda\n",
                        "   GPU: Tesla T4\n"
                    ]
                }
            ],
            "source": [
                "# 2. Imports\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torchvision.datasets import EMNIST\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "import numpy as np\n",
                "from tqdm.notebook import tqdm\n",
                "import json\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"ğŸ® Device: {device}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ¯ Parameters: 11,314,942\n"
                    ]
                }
            ],
            "source": [
                "# 3. SUPER Model Architecture (Deeper ResNet)\n",
                "class ResidualBlock(nn.Module):\n",
                "    def __init__(self, in_channels, out_channels, stride=1):\n",
                "        super(ResidualBlock, self).__init__()\n",
                "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
                "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
                "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
                "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
                "        \n",
                "        self.shortcut = nn.Sequential()\n",
                "        if stride != 1 or in_channels != out_channels:\n",
                "            self.shortcut = nn.Sequential(\n",
                "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
                "                nn.BatchNorm2d(out_channels)\n",
                "            )\n",
                "\n",
                "    def forward(self, x):\n",
                "        out = F.relu(self.bn1(self.conv1(x)))\n",
                "        out = self.bn2(self.conv2(out))\n",
                "        out += self.shortcut(x)\n",
                "        out = F.relu(out)\n",
                "        return out\n",
                "\n",
                "class CharCNN_v3_SUPER(nn.Module):\n",
                "    \"\"\"Deeper model with more capacity\"\"\"\n",
                "    def __init__(self, num_classes=62, dropout_rate=0.4):\n",
                "        super(CharCNN_v3_SUPER, self).__init__()\n",
                "        \n",
                "        # Initial conv\n",
                "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
                "        self.bn1 = nn.BatchNorm2d(64)\n",
                "        \n",
                "        # Deeper ResNet blocks\n",
                "        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n",
                "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
                "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
                "        self.layer4 = self._make_layer(256, 512, 2, stride=2)  # Extra layer\n",
                "        \n",
                "        # Classifier\n",
                "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
                "        self.fc = nn.Sequential(\n",
                "            nn.Dropout(dropout_rate),\n",
                "            nn.Linear(512, 256),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(dropout_rate * 0.5),\n",
                "            nn.Linear(256, num_classes)\n",
                "        )\n",
                "\n",
                "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
                "        layers = []\n",
                "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
                "        for _ in range(1, num_blocks):\n",
                "            layers.append(ResidualBlock(out_channels, out_channels, 1))\n",
                "        return nn.Sequential(*layers)\n",
                "\n",
                "    def forward(self, x):\n",
                "        out = F.relu(self.bn1(self.conv1(x)))\n",
                "        out = self.layer1(out)\n",
                "        out = self.layer2(out)\n",
                "        out = self.layer3(out)\n",
                "        out = self.layer4(out)\n",
                "        out = self.avg_pool(out)\n",
                "        out = out.view(out.size(0), -1)\n",
                "        out = self.fc(out)\n",
                "        return out\n",
                "\n",
                "model = CharCNN_v3_SUPER().to(device)\n",
                "print(f\"ğŸ¯ Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipython-input-3996947078.py:6: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
                        "  A.GaussNoise(var_limit=(5, 20), p=0.2),\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“¥ Downloading EMNIST (full dataset)...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 562M/562M [00:06<00:00, 88.1MB/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“Š Train: 697,932 | Test: 116,323\n"
                    ]
                }
            ],
            "source": [
                "# 4. Data Augmentation with Albumentations\n",
                "train_transform = A.Compose([\n",
                "    A.ElasticTransform(p=0.3),\n",
                "    A.GridDistortion(p=0.2),\n",
                "    A.Affine(rotate=(-15, 15), translate_percent=0.1, scale=(0.9, 1.1), p=0.5),\n",
                "    A.GaussNoise(var_limit=(5, 20), p=0.2),\n",
                "])\n",
                "\n",
                "class EMNISTAugmented(Dataset):\n",
                "    def __init__(self, dataset, transform=None):\n",
                "        self.dataset = dataset\n",
                "        self.transform = transform\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.dataset)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        img, label = self.dataset[idx]\n",
                "        img_np = np.array(img).transpose()  # Fix EMNIST orientation\n",
                "        \n",
                "        if self.transform:\n",
                "            augmented = self.transform(image=img_np)\n",
                "            img_np = augmented['image']\n",
                "        \n",
                "        img_tensor = torch.from_numpy(img_np).float() / 255.0\n",
                "        img_tensor = img_tensor.unsqueeze(0)\n",
                "        return img_tensor, label\n",
                "\n",
                "print(\"ğŸ“¥ Downloading EMNIST (full dataset)...\")\n",
                "train_dataset_raw = EMNIST(root='./data', split='byclass', train=True, download=True)\n",
                "test_dataset_raw = EMNIST(root='./data', split='byclass', train=False, download=True)\n",
                "\n",
                "train_dataset = EMNISTAugmented(train_dataset_raw, transform=train_transform)\n",
                "test_dataset = EMNISTAugmented(test_dataset_raw, transform=None)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
                "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
                "\n",
                "print(f\"ğŸ“Š Train: {len(train_dataset):,} | Test: {len(test_dataset):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“ˆ Training for 30 epochs with OneCycleLR\n"
                    ]
                }
            ],
            "source": [
                "# 5. Training Setup\n",
                "EPOCHS = 30\n",
                "LEARNING_RATE = 0.001\n",
                "\n",
                "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label smoothing for better generalization\n",
                "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
                "scheduler = optim.lr_scheduler.OneCycleLR(\n",
                "    optimizer,\n",
                "    max_lr=0.01,\n",
                "    epochs=EPOCHS,\n",
                "    steps_per_epoch=len(train_loader),\n",
                "    pct_start=0.3\n",
                ")\n",
                "\n",
                "print(f\"ğŸ“ˆ Training for {EPOCHS} epochs with OneCycleLR\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f68f8a7264c94244bb6df08e357415ef",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Epoch 1/30:   0%|          | 0/2727 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3e98684f41e6495f98b41a6d305d35d0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation:   0%|          | 0/455 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ“Š Epoch 1: Train=81.89% | Test=85.80%\n",
                        "âœ… New best: 85.80%\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ba3acb13e73340109319c43380835b74",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Epoch 2/30:   0%|          | 0/2727 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3e07d08db61945928825cc05ade8ff6a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation:   0%|          | 0/455 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ“Š Epoch 2: Train=84.62% | Test=85.90%\n",
                        "âœ… New best: 85.90%\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e945205d77b94ee986364ce78c57405b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Epoch 3/30:   0%|          | 0/2727 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a9bf6780004a40c49f5510e84394ffbf",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation:   0%|          | 0/455 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ“Š Epoch 3: Train=84.91% | Test=86.52%\n",
                        "âœ… New best: 86.52%\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2a2b22a7020b406d9c911d7c9afc7be0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Epoch 4/30:   0%|          | 0/2727 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9aafbee4bab34f44ae5526adf405e564",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation:   0%|          | 0/455 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ“Š Epoch 4: Train=85.16% | Test=85.96%\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e1e0772388e24a7aa33a0ebe208250b8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Epoch 5/30:   0%|          | 0/2727 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2efd6590f6f3466bac1882438306c9c2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation:   0%|          | 0/455 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ğŸ“Š Epoch 5: Train=85.30% | Test=86.51%\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "24fcb4de413f4fc5a31c8ebd1a4b013e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Epoch 6/30:   0%|          | 0/2727 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# 6. Training Loop\n",
                "best_acc = 0.0\n",
                "history = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    # Training\n",
                "    model.train()\n",
                "    train_loss = 0.0\n",
                "    train_correct = 0\n",
                "    train_total = 0\n",
                "    \n",
                "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
                "    for images, labels in pbar:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        scheduler.step()\n",
                "        \n",
                "        train_loss += loss.item()\n",
                "        _, predicted = outputs.max(1)\n",
                "        train_total += labels.size(0)\n",
                "        train_correct += predicted.eq(labels).sum().item()\n",
                "        \n",
                "        pbar.set_postfix({\n",
                "            'loss': f\"{loss.item():.4f}\",\n",
                "            'acc': f\"{100.*train_correct/train_total:.2f}%\",\n",
                "            'lr': f\"{scheduler.get_last_lr()[0]:.6f}\"\n",
                "        })\n",
                "    \n",
                "    train_acc = 100. * train_correct / train_total\n",
                "    \n",
                "    # Validation\n",
                "    model.eval()\n",
                "    test_correct = 0\n",
                "    test_total = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for images, labels in tqdm(test_loader, desc=\"Validation\", leave=False):\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            outputs = model(images)\n",
                "            _, predicted = outputs.max(1)\n",
                "            test_total += labels.size(0)\n",
                "            test_correct += predicted.eq(labels).sum().item()\n",
                "    \n",
                "    test_acc = 100. * test_correct / test_total\n",
                "    \n",
                "    history['train_loss'].append(train_loss / len(train_loader))\n",
                "    history['train_acc'].append(train_acc)\n",
                "    history['test_acc'].append(test_acc)\n",
                "    \n",
                "    print(f\"\\nğŸ“Š Epoch {epoch+1}: Train={train_acc:.2f}% | Test={test_acc:.2f}%\")\n",
                "    \n",
                "    if test_acc > best_acc:\n",
                "        best_acc = test_acc\n",
                "        torch.save(model.state_dict(), 'best_model_v3_super.pth')\n",
                "        print(f\"âœ… New best: {test_acc:.2f}%\")\n",
                "\n",
                "print(f\"\\nğŸ‰ Training complete! Best: {best_acc:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Save Config\n",
                "config = {\n",
                "    'num_classes': 62,\n",
                "    'dropout_rate': 0.4,\n",
                "    'model_version': 'v3_super',\n",
                "    'best_test_acc': best_acc,\n",
                "    'epochs_trained': EPOCHS,\n",
                "    'architecture': 'ResNet-SUPER (8 blocks)',\n",
                "    'parameters': sum(p.numel() for p in model.parameters())\n",
                "}\n",
                "\n",
                "with open('config_v3_super.json', 'w') as f:\n",
                "    json.dump(config, f, indent=4)\n",
                "\n",
                "print(\"ğŸ’¾ Config saved\")\n",
                "print(json.dumps(config, indent=2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8. Export to ONNX\n",
                "import os\n",
                "\n",
                "print(\"ğŸ”„ Exporting to ONNX...\")\n",
                "\n",
                "model_path = 'best_model_v3_super.pth'\n",
                "if not os.path.exists(model_path):\n",
                "    raise FileNotFoundError(f\"âŒ No se encontrÃ³ el archivo {model_path}. AsegÃºrate de que el entrenamiento haya terminado correctamente.\")\n",
                "\n",
                "# Load best model\n",
                "print(f\"   Loading model from {model_path}...\")\n",
                "model.load_state_dict(torch.load(model_path))\n",
                "model.eval()\n",
                "\n",
                "# Dummy input on GPU (device)\n",
                "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
                "\n",
                "try:\n",
                "    torch.onnx.export(\n",
                "        model,\n",
                "        dummy_input,\n",
                "        'model_v3_super.onnx',\n",
                "        export_params=True,\n",
                "        opset_version=11,\n",
                "        do_constant_folding=True,\n",
                "        input_names=['input'],\n",
                "        output_names=['output'],\n",
                "        dynamic_axes={\n",
                "            'input': {0: 'batch_size'},\n",
                "            'output': {0: 'batch_size'}\n",
                "        }\n",
                "    )\n",
                "    print(\"âœ… ONNX exported successfully!\")\n",
                "except Exception as e:\n",
                "    print(f\"âŒ Error exporting to ONNX: {e}\")\n",
                "    raise e\n",
                "\n",
                "# Test ONNX\n",
                "print(\"   Verifying ONNX model...\")\n",
                "import onnxruntime as ort\n",
                "try:\n",
                "    # ONNX Runtime usually runs on CPU by default unless configured otherwise, which is fine for verification\n",
                "    session = ort.InferenceSession('model_v3_super.onnx')\n",
                "    test_input = np.random.randn(1, 1, 28, 28).astype(np.float32)\n",
                "    outputs = session.run(None, {'input': test_input})\n",
                "    print(f\"âœ… ONNX verified: output shape {outputs[0].shape}\")\n",
                "except Exception as e:\n",
                "    print(f\"âŒ Error verifying ONNX model: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 9. Download Files\n",
                "from google.colab import files\n",
                "\n",
                "print(\"ğŸ“¥ Descargando modelo ONNX...\")\n",
                "files.download('model_v3_super.onnx')\n",
                "files.download('config_v3_super.json')\n",
                "\n",
                "print(\"\\nâœ… Archivos descargados!\")\n",
                "print(\"\\nğŸ“Œ Instrucciones:\")\n",
                "print(\"1. Coloca 'model_v3_super.onnx' en: models/cnn_modelo_v3/model.onnx\")\n",
                "print(\"2. Coloca 'config_v3_super.json' en: models/cnn_modelo_v3/config_v3.json\")\n",
                "print(\"3. La API cargarÃ¡ automÃ¡ticamente el nuevo modelo!\")\n",
                "print(f\"\\nğŸ¯ Accuracy final: {best_acc:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ‰ Â¡Listo!\n",
                "\n",
                "Modelo **v3 SUPER** entrenado con:\n",
                "- Arquitectura mÃ¡s profunda (ResNet con 8 bloques)\n",
                "- Data augmentation avanzado\n",
                "- OneCycleLR para mejor convergencia\n",
                "- Label smoothing\n",
                "- TODO el dataset EMNIST\n",
                "\n",
                "**PrÃ³ximos pasos:**\n",
                "1. Descarga los archivos\n",
                "2. ColÃ³calos en tu proyecto local\n",
                "3. Â¡Usa el modelo en la API! ğŸš€"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
