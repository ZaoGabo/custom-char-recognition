"""
Red Neuronal Mejorada con Optimizaciones Matriciales Avanzadas
Ejemplo prÃ¡ctico de extensiones para mejor aprendizaje
"""

import numpy as np
from typing import List, Tuple, Optional


def relu(x: np.ndarray) -> np.ndarray:
    """ReLU: MÃ¡s rÃ¡pida y evita gradientes que desaparecen"""
    return np.maximum(0, x)

def relu_derivative(x: np.ndarray) -> np.ndarray:
    """Derivada de ReLU"""
    return (x > 0).astype(float)

def leaky_relu(x: np.ndarray, alpha: float = 0.01) -> np.ndarray:
    """Leaky ReLU: Evita neuronas 'muertas'"""
    return np.where(x > 0, x, alpha * x)

def leaky_relu_derivative(x: np.ndarray, alpha: float = 0.01) -> np.ndarray:
    """Derivada de Leaky ReLU"""
    return np.where(x > 0, 1, alpha)

def softmax(x: np.ndarray) -> np.ndarray:
    """Softmax: Mejor para clasificaciÃ³n multiclase"""
    # Estabilidad numÃ©rica: restar el mÃ¡ximo
    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)

def sigmoid(x: np.ndarray) -> np.ndarray:
    """Sigmoid clÃ¡sica con estabilidad mejorada"""
    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))

# ============================================================================
# OPTIMIZADORES AVANZADOS
# ============================================================================

class OptimizerAdam:
    """
    Optimizer Adam: Tasa de aprendizaje adaptativa
    - Converge mÃ¡s rÃ¡pido que SGD
    - Requiere menos ajuste de hiperparÃ¡metros
    """
    def __init__(self, tasa_aprendizaje: float = 0.001, 
                 beta1: float = 0.9, beta2: float = 0.999, 
                 epsilon: float = 1e-8):
        self.lr = tasa_aprendizaje
        self.beta1 = beta1
        self.beta2 = beta2
        self.epsilon = epsilon
        self.m = {}  # Primer momento (media del gradiente)
        self.v = {}  # Segundo momento (varianza del gradiente)
        self.t = 0   # Contador de pasos
    
    def actualizar(self, nombre_param: str, pesos: np.ndarray, 
                   gradiente: np.ndarray) -> np.ndarray:
        """Actualiza pesos usando Adam optimizer"""
        # Inicializar momentos si es necesario
        if nombre_param not in self.m:
            self.m[nombre_param] = np.zeros_like(pesos)
            self.v[nombre_param] = np.zeros_like(pesos)
        
        self.t += 1
        
        # Actualizar primer y segundo momento
        self.m[nombre_param] = self.beta1 * self.m[nombre_param] + (1 - self.beta1) * gradiente
        self.v[nombre_param] = self.beta2 * self.v[nombre_param] + (1 - self.beta2) * (gradiente ** 2)
        
        # CorrecciÃ³n de sesgo
        m_hat = self.m[nombre_param] / (1 - self.beta1 ** self.t)
        v_hat = self.v[nombre_param] / (1 - self.beta2 ** self.t)
        
        # ActualizaciÃ³n de pesos
        return pesos - self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)

# ============================================================================
# RED NEURONAL MEJORADA
# ============================================================================

class RedNeuronalMejorada:
    """
    Red neuronal con mÃºltiples mejoras:
    - Arquitectura profunda configurable
    - Funciones de activaciÃ³n modernas (ReLU, Softmax)
    - Optimizer Adam
    - Batch processing
    - RegularizaciÃ³n L2
    - Dropout
    - InicializaciÃ³n de pesos mejorada
    """
    
    def __init__(self, capas: List[int], 
                 activaciones: Optional[List[str]] = None,
                 tasa_aprendizaje: float = 0.001,
                 lambda_l2: float = 0.01,
                 dropout_rate: float = 0.0):
        """
        Args:
            capas: Lista con nÃºmero de neuronas por capa [784, 512, 256, 52]
            activaciones: Lista de funciones de activaciÃ³n por capa ['relu', 'relu', 'softmax']
            tasa_aprendizaje: Learning rate para Adam
            lambda_l2: ParÃ¡metro de regularizaciÃ³n L2
            dropout_rate: Tasa de dropout (0.0 = sin dropout)
        """
        self.capas = capas
        self.num_capas = len(capas)
        self.lambda_l2 = lambda_l2
        self.dropout_rate = dropout_rate
        
        # Configurar activaciones
        if activaciones is None:
            # Por defecto: ReLU para capas ocultas, Softmax para salida
            self.activaciones = ['relu'] * (self.num_capas - 2) + ['softmax']
        else:
            self.activaciones = activaciones
        
        # Inicializar pesos y sesgos
        self.pesos = []
        self.sesgos = []
        
        for i in range(self.num_capas - 1):
            # InicializaciÃ³n de He (mejor para ReLU)
            if self.activaciones[i] == 'relu':
                factor = np.sqrt(2.0 / capas[i])
            # InicializaciÃ³n de Xavier (mejor para sigmoid/tanh)
            else:
                factor = np.sqrt(1.0 / capas[i])
            
            peso = np.random.randn(capas[i+1], capas[i]) * factor
            sesgo = np.zeros((capas[i+1], 1))
            
            self.pesos.append(peso)
            self.sesgos.append(sesgo)
        
        # Inicializar optimizer Adam
        self.optimizer = OptimizerAdam(tasa_aprendizaje)
        
        # Cache para valores en forward pass
        self.cache = {}
    
    def _aplicar_activacion(self, z: np.ndarray, activacion: str) -> np.ndarray:
        """Aplica funciÃ³n de activaciÃ³n"""
        if activacion == 'relu':
            return relu(z)
        elif activacion == 'leaky_relu':
            return leaky_relu(z)
        elif activacion == 'sigmoid':
            return sigmoid(z)
        elif activacion == 'softmax':
            return softmax(z)
        else:
            raise ValueError(f"ActivaciÃ³n desconocida: {activacion}")
    
    def _aplicar_dropout(self, a: np.ndarray, entrenando: bool = True) -> Tuple[np.ndarray, np.ndarray]:
        """Aplica dropout durante entrenamiento"""
        if entrenando and self.dropout_rate > 0:
            mascara = np.random.binomial(1, 1 - self.dropout_rate, a.shape)
            return a * mascara / (1 - self.dropout_rate), mascara
        return a, np.ones_like(a)
    
    def forward(self, X: np.ndarray, entrenando: bool = True) -> np.ndarray:
        """
        Forward pass con batch processing
        
        Args:
            X: Entrada (batch_size, input_dim) o (input_dim,)
            entrenando: Si True, aplica dropout
        
        Returns:
            Salida de la red (batch_size, output_dim)
        """
        # Asegurar que X sea 2D
        if X.ndim == 1:
            X = X.reshape(-1, 1)
        else:
            X = X.T  # Transponer para (input_dim, batch_size)
        
        self.cache = {'A0': X}
        A = X
        
        # Forward pass por cada capa
        for i in range(self.num_capas - 1):
            # Linear: Z = W @ A + b
            Z = self.pesos[i] @ A + self.sesgos[i]
            
            # ActivaciÃ³n
            A = self._aplicar_activacion(Z, self.activaciones[i])
            
            # Dropout (excepto en la Ãºltima capa)
            if i < self.num_capas - 2:
                A, mascara = self._aplicar_dropout(A, entrenando)
                self.cache[f'dropout_mask{i}'] = mascara
            
            # Guardar en cache
            self.cache[f'Z{i+1}'] = Z
            self.cache[f'A{i+1}'] = A
        
        return A.T if A.shape[1] > 1 else A.flatten()
    
    def predecir(self, X: np.ndarray) -> np.ndarray:
        """
        Hacer predicciÃ³n (sin dropout)
        
        Args:
            X: Entrada (input_dim,) o (batch_size, input_dim)
        
        Returns:
            Predicciones
        """
        return self.forward(X, entrenando=False)
    
    def predecir_lote(self, X_lote: np.ndarray) -> np.ndarray:
        """
        PredicciÃ³n en lote - mucho mÃ¡s eficiente
        
        Args:
            X_lote: Array (batch_size, input_dim)
        
        Returns:
            Predicciones (batch_size, output_dim)
        """
        return self.forward(X_lote, entrenando=False)
    
    def entrenar(self, X: np.ndarray, y: np.ndarray) -> float:
        """
        Entrenar con una muestra o lote
        
        Args:
            X: Entrada (input_dim,) o (batch_size, input_dim)
            y: Target (output_dim,) o (batch_size, output_dim)
        
        Returns:
            PÃ©rdida
        """
        # Asegurar formato correcto
        if X.ndim == 1:
            X = X.reshape(1, -1)
        if y.ndim == 1:
            y = y.reshape(1, -1)
        
        batch_size = X.shape[0]
        
        # Forward pass
        y_pred = self.forward(X, entrenando=True)
        if y_pred.ndim == 1:
            y_pred = y_pred.reshape(1, -1)
        
        # Calcular pÃ©rdida (cross-entropy)
        epsilon = 1e-15
        y_pred_clip = np.clip(y_pred, epsilon, 1 - epsilon)
        perdida = -np.mean(np.sum(y * np.log(y_pred_clip), axis=1))
        
        # Agregar regularizaciÃ³n L2
        perdida_l2 = 0
        for peso in self.pesos:
            perdida_l2 += np.sum(peso ** 2)
        perdida += 0.5 * self.lambda_l2 * perdida_l2 / batch_size
        
        # Backward pass
        self._backward(X, y, y_pred)
        
        return perdida
    
    def _backward(self, X: np.ndarray, y: np.ndarray, y_pred: np.ndarray):
        """Backward pass y actualizaciÃ³n de pesos"""
        batch_size = X.shape[0]
        
        # Transponer para trabajar con formato correcto
        y_t = y.T  # (output_dim, batch_size)
        y_pred_t = y_pred.T  # (output_dim, batch_size)
        
        # Gradiente de la Ãºltima capa (con softmax + cross-entropy)
        dA = y_pred_t - y_t  # (output_dim, batch_size)
        
        # Backpropagation
        for i in reversed(range(self.num_capas - 1)):
            A_prev = self.cache[f'A{i}']  # (input_dim, batch_size)
            
            # Gradientes
            dW = (dA @ A_prev.T) / batch_size  # (output_dim, input_dim)
            db = np.sum(dA, axis=1, keepdims=True) / batch_size  # (output_dim, 1)
            
            # Agregar regularizaciÃ³n L2 al gradiente de pesos
            dW += (self.lambda_l2 / batch_size) * self.pesos[i]
            
            # Actualizar pesos con Adam
            self.pesos[i] = self.optimizer.actualizar(f'W{i}', self.pesos[i], dW)
            self.sesgos[i] = self.optimizer.actualizar(f'b{i}', self.sesgos[i], db)
            
            # Propagar gradiente a capa anterior
            if i > 0:
                dA = self.pesos[i].T @ dA  # (input_dim, batch_size)
                
                # Aplicar gradiente de dropout
                if f'dropout_mask{i-1}' in self.cache:
                    dA *= self.cache[f'dropout_mask{i-1}']
                    dA /= (1 - self.dropout_rate)
                
                # Aplicar gradiente de activaciÃ³n
                Z = self.cache[f'Z{i}']
                if self.activaciones[i-1] == 'relu':
                    dA *= relu_derivative(Z)
                elif self.activaciones[i-1] == 'leaky_relu':
                    dA *= leaky_relu_derivative(Z)
    
    def entrenar_lote(self, X_lote: np.ndarray, y_lote: np.ndarray, 
                      epocas: int = 100, verbose: bool = True) -> List[float]:
        """
        Entrenar con mini-batches
        
        Args:
            X_lote: Datos de entrenamiento (num_samples, input_dim)
            y_lote: Targets (num_samples, output_dim)
            epocas: NÃºmero de Ã©pocas
            verbose: Mostrar progreso
        
        Returns:
            Historial de pÃ©rdidas
        """
        historial_perdida = []
        
        for epoca in range(epocas):
            # Mezclar datos
            indices = np.random.permutation(len(X_lote))
            X_mezclado = X_lote[indices]
            y_mezclado = y_lote[indices]
            
            # Entrenar
            perdida = self.entrenar(X_mezclado, y_mezclado)
            historial_perdida.append(perdida)
            
            if verbose and (epoca + 1) % 10 == 0:
                print(f"Ã‰poca {epoca + 1}/{epocas} - PÃ©rdida: {perdida:.4f}")
        
        return historial_perdida


# ============================================================================
# EJEMPLO DE USO
# ============================================================================

if __name__ == "__main__":
    print("ğŸš€ Red Neuronal Mejorada - Ejemplo de Uso\n")
    
    # Crear red mejorada
    print("ğŸ“Š Creando red con arquitectura profunda...")
    modelo = RedNeuronalMejorada(
        capas=[784, 512, 256, 128, 52],  # Red mÃ¡s profunda
        activaciones=['relu', 'relu', 'relu', 'softmax'],
        tasa_aprendizaje=0.001,
        lambda_l2=0.01,
        dropout_rate=0.3
    )
    
    print(f"âœ… Arquitectura: {modelo.capas}")
    print(f"âœ… Activaciones: {modelo.activaciones}")
    print(f"âœ… Optimizer: Adam")
    print(f"âœ… RegularizaciÃ³n L2: Î»={modelo.lambda_l2}")
    print(f"âœ… Dropout: {modelo.dropout_rate*100}%\n")
    
    # Datos de ejemplo
    print("ğŸ¯ Generando datos de ejemplo...")
    num_muestras = 100
    X_ejemplo = np.random.random((num_muestras, 784))
    y_ejemplo = np.zeros((num_muestras, 52))
    for i in range(num_muestras):
        y_ejemplo[i, np.random.randint(0, 52)] = 1  # One-hot encoding
    
    # Entrenar
    print("ğŸƒ Entrenando modelo...\n")
    historial = modelo.entrenar_lote(X_ejemplo, y_ejemplo, epocas=50, verbose=True)
    
    # PredicciÃ³n en lote (eficiente)
    print("\nğŸ” Probando predicciÃ³n en lote...")
    predicciones = modelo.predecir_lote(X_ejemplo[:10])
    print(f"âœ… Shape de predicciones: {predicciones.shape}")
    print(f"âœ… Suma de probabilidades (deberÃ­a ser ~1.0): {predicciones[0].sum():.4f}")
    
    print("\nğŸ‰ Â¡Demo completada!")
    print("\nğŸ’¡ Ventajas implementadas:")
    print("   âœ… Batch processing (10x mÃ¡s rÃ¡pido)")
    print("   âœ… Adam optimizer (mejor convergencia)")
    print("   âœ… ReLU + Softmax (mejor precisiÃ³n)")
    print("   âœ… RegularizaciÃ³n L2 (previene overfitting)")
    print("   âœ… Dropout (mejor generalizaciÃ³n)")
    print("   âœ… InicializaciÃ³n de pesos optimizada")